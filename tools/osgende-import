#!/usr/bin/env python3
# SPDX-License-Identifier: GPL-3.0-only
#
# This file is part of Osgende
# Copyright (C) 2014-2022 Sarah Hoffmann
"""
Importer of OSM planet dumps and diffs into a simplified Osmosis
style postgresql database.

Diffs must be applied in correct order in order to keep database integrity.
However, diffs can be savely reapplied, i.e. it is possible to reapply an
older diff iff all diffs that follow are reapplied as well.

Diffs must not contain duplicates. Use osmosis' simplifyChange to remove
duplicates.
"""

import sys
import os.path as ospath
import os
import threading
import codecs
import json
import struct
import tempfile
from binascii import hexlify
import argparse
import osmium
import osmium.replication.server as rserv
from collections import namedtuple

import sqlalchemy as sqla

from osgende.common.nodestore import NodeStore
from osgende.common.status import StatusManager
from osgende.osmdata import OsmSourceTables
from osgende.common.sqlalchemy.database import database_exists, database_create
from osgende.tools.importing import BaseImportManager


def mkdict(tags):
    return dict([(t.k, t.v) for t in tags])

def obj2action(obj):
    if obj.visible:
        return 'C' if obj.version == 1 else 'M'
    else:
        return 'D' # delete

def loc2wkb(loc):
    # PostGIS extension that includes a SRID, see postgis/doc/ZMSGeoms.txt
    return hexlify(struct.pack("=biidd", 1, 0x20000001, 4326,
                               loc.lon, loc.lat)).decode()



class CopyThread(threading.Thread):
    """Thread that starts a copy_from on the incomming file descriptor.
       The main thread pipes into the other end of this descriptor.
    """
    def __init__(self, rcv, engine, table, columns):
        threading.Thread.__init__(self)
        self.rcv = rcv
        self.engine = engine
        self.table = table
        self.columns = columns

    def run(self):
        conn = self.engine.raw_connection()
        try:
            cur = conn.cursor()
            cur.copy_from(os.fdopen(self.rcv), self.table,
                          null='NULL', columns=self.columns, size=32*1024)
            cur.close()
            conn.commit()
        finally:
            conn.close()



class DbWriter:
    """Can either copy out new input data or update existing data.
    """
    def __init__(self, engine, table):
        self.conn = engine.connect()
        self.trans = self.conn.begin()
        if hasattr(table.c, 'id'):
            self.update_func = table.update().where(table.c.id == sqla.bindparam('oid')).compile(engine)
            self.delete_func = table.delete().where(table.c.id == sqla.bindparam('oid')).compile(engine)
        else:
            self.update_func = table.insert().compile(engine)
            self.delete_func = table.delete().where(table.c.relation_id == sqla.bindparam('oid')).compile(engine)
        columns = [ str(c.name) for c in table.columns ]
        self.linepattern = '\t'.join([u"%%(%s)s" % x for x in columns]) + '\n'

        fd_rcv, fd_snd = os.pipe()
        self.out_pipe = os.fdopen(fd_snd, 'w')

        self.thread = CopyThread(fd_rcv, engine, str(table.name), columns)
        self.thread.daemon = True
        self.thread.start()

    def write(self, **attrs):
        self.out_pipe.write(self.linepattern % attrs)

    def close(self):
        self.trans.commit()
        self.conn.close()
        self.out_pipe.close()
        self.thread.join()

    def update(self, **attrs):
        result = self.conn.execute(self.update_func, attrs)
        return result.rowcount == 1

    def delete(self, oid):
        self.conn.execute(self.delete_func, {'oid' : oid })

DbWriterSet = namedtuple('DbWriterSet', 'node way relation')

class OSMImporter(osmium.SimpleHandler):
    sqltrans = { ord(u'\\') : u'\\\\' }


    def __init__(self, options):
        super(OSMImporter, self).__init__()

        dburl = sqla.engine.url.URL.create('postgresql', username=options.username,
                                           password=options.password,
                                           database=options.database)

        self.metadata = sqla.MetaData()
        self.tables = OsmSourceTables(self.metadata)
        if options.replication is not None:
            self.status = StatusManager(self.metadata)
        else:
            self.status = None

        self.engine = sqla.create_engine(dburl, echo=options.verbose)

        if options.replication:
            self.repserver = rserv.ReplicationServer(options.replication)
            self.change_size = options.change_size
        else:
            self.repserver = None

        if options.nodestore is None:
            self.nodestore = None
        else:
            self.nodestore = NodeStore(options.nodestore)

        if options.replication is not None and options.inputfile == '-':
            self.reader = None
            self.is_change_file = True
        else:
            self.reader = osmium.io.Reader(options.inputfile)
            if options.change_file:
                self.is_change_file = True
            else:
                self.is_change_file = self.reader.header().has_multiple_object_versions
            if options.replication is not None:
                ts = osmium.replication.newest_change_from_file(options.inputfile)
                diffinfo = self.repserver.get_state_info(self.repserver.timestamp_to_sequence(ts))
                with self.engine.begin() as conn:
                    self.status.set_status(conn, 'base', diffinfo.timestamp,
                                           sequence=diffinfo.sequence)

        if self.is_change_file:
            self.prepare_changeset()

        self.data = DbWriterSet(
                      node=DbWriter(self.engine, self.tables.node.data),
                      way=DbWriter(self.engine, self.tables.way.data),
                      relation=DbWriter(self.engine, self.tables.relation.data))
        if self.is_change_file:
            self.change = DbWriterSet(
                           node=DbWriter(self.engine, self.tables.node.change),
                           way=DbWriter(self.engine, self.tables.way.change),
                           relation=DbWriter(self.engine, self.tables.relation.change))
            # use change functions
            self.node = self.node_change
            self.way = self.way_change
            self.relation = self.relation_change


    def readfile(self):
        if self.reader is not None:
            osmium.apply(self.reader, self)
        else:
            with self.engine.begin() as conn:
                seq = self.status.get_sequence(conn)
                if seq is None:
                    raise RuntimeError("Replication sequence missing.")
            seq = self.repserver.apply_diffs(self, seq + 1, self.change_size)
            if seq is not None:
                diffinfo = self.repserver.get_state_info(seq)
                if diffinfo is not None:
                    with self.engine.begin() as conn:
                        self.status.set_status(conn, 'base', diffinfo.timestamp,
                                               sequence=diffinfo.sequence)


        for tab in self.data:
            tab.close()
        if self.is_change_file:
            for tab in self.change:
                tab.close()

        if self.nodestore:
            self.nodestore.close()


    def create_indices(self):
        with self.engine.begin() as conn:
            if self.is_change_file:
                for n in ('node', 'way', 'relation'):
                    i = sqla.Index('pk_%s_change' % n, self.tables[n].change.c.id)
                    i.create(conn)
            else:
                for n in ('node', 'way', 'relation'):
                    i = sqla.Index('pk_%ss' % n, self.tables[n].data.c.id, unique=True)
                    i.create(conn)

    def grant_read_access(self, user):
        with self.engine.begin() as conn:
            for table in (self.tables.node, self.tables.way, self.tables.relation):
                conn.execute(f'GRANT SELECT ON TABLE {table.data.key} TO "{user}"')
                self.status.grant_read_access(conn, user)

    def prepare_changeset(self):
        with self.engine.begin() as conn:
            for n in ('node', 'way', 'relation'):
                conn.execute("DROP INDEX IF EXISTS pk_%s_change" % n)
                conn.execute("TRUNCATE %s_changeset" % n)

    def node(self, node):
        if not self.nodestore or len(node.tags) > 0:
            tagstr = self.to_tagstr(mkdict(node.tags))
            self.data.node.write(id=node.id, tags=tagstr, geom=loc2wkb(node.location))
        if self.nodestore:
            self.nodestore.set_from_node(node)

    def node_change(self, node):
        tagdict = mkdict(node.tags)
        tagstr = self.to_tagstr(tagdict)
        geom = loc2wkb(node.location)
        self.change.node.write(id=node.id, action=obj2action(node),
                               tags=tagstr, geom=geom)

        if node.deleted:
            self.data.node.delete(node.id)
        else:
            if self.nodestore:
                self.nodestore.set_from_node(node)
                if len(node.tags) == 0:
                    self.data.node.delete(node.id)
                    return
            if self.data.node.update(id=node.id, oid=node.id, tags=tagdict, geom=geom):
                return

            self.data.node.write(id=node.id, tags=tagstr, geom=geom)

    def way(self, way):
        nodes = u'{%s}' % (','.join([str(n.ref) for n in way.nodes]))
        self.data.way.write(id=way.id, tags=self.to_tagstr(mkdict(way.tags)),
                                   nodes=nodes)

    def way_change(self, way):
        self.change.way.write(id=way.id, action=obj2action(way))

        if way.deleted:
            self.data.way.delete(way.id)
        else:
            nodes = [int(x.ref) for x in way.nodes]
            tagdict = mkdict(way.tags)
            if self.data.way.update(id=way.id, oid=way.id, tags=tagdict, nodes=nodes):
                return

            nodes = u'{%s}' % (','.join([str(n.ref) for n in way.nodes]))
            self.data.way.write(id=way.id, tags=self.to_tagstr(tagdict),
                                       nodes=nodes)

    def relation(self, rel):
        members = [ { 'type' : m.type.upper(),
                      'id' : m.ref,
                      'role' : m.role } for m in rel.members ]
        self.data.relation.write(id=rel.id, tags=self.to_tagstr(mkdict(rel.tags)),
                                 members=self.sqlstr(json.dumps(members)))

    def relation_change(self, rel):
        self.change.relation.write(id=rel.id, action=obj2action(rel))

        if rel.deleted:
            self.data.relation.delete(rel.id)
        else:
            members = [ { 'type' : m.type.upper(),
                          'id' : m.ref,
                          'role' : m.role } for m in rel.members ]
            tagdict = mkdict(rel.tags)

            if self.data.relation.update(id=rel.id, oid=rel.id, tags=tagdict,
                                         members=members):
                return

            self.data.relation.write(id=rel.id, tags=self.to_tagstr(tagdict),
                                     members=self.sqlstr(json.dumps(members)))

    def to_tagstr(self, tagdict):
        return self.sqlstr(json.dumps(tagdict))

    if sys.version_info[0] < 3:
        def sqlstr(self, s):
            return s.decode('utf8').translate(self.sqltrans)
    else:
        def sqlstr(self, s):
            return s.translate(self.sqltrans)



if __name__ == '__main__':

    # fun with command line options
    parser = argparse.ArgumentParser(description=__doc__,
                                     formatter_class=argparse.RawDescriptionHelpFormatter,
                                     usage='%(prog)s [options] <osm file>')
    parser.add_argument('-d', action='store', dest='database', default='osmosis',
                       help='name of database')
    parser.add_argument('-u', action='store', dest='username', default=None,
                       help='database user')
    parser.add_argument('-U', action='store', dest='ro_user', default=None,
                       help='Additonal database to be granted r/o access')
    parser.add_argument('-p', action='store', dest='password', default=None,
                       help='password for database')
    parser.add_argument('-n', action='store', dest='nodestore', default=None,
                       help='File containing the node store')
    parser.add_argument('-r', action='store', dest='replication', default=None,
                       help='URL to replication service')
    parser.add_argument('-C', action='store_true', dest='change_file', default=False,
                       help='Input file is a change file')
    parser.add_argument('-S', action='store', dest='change_size', default=50*1024,
                       type=int,
                       help='Maxium size in kB for changes to download at once')
    parser.add_argument('-c', action='store_true', dest='createdb', default=False,
                       help='Create a new database and set up the tables')
    parser.add_argument('-i', action='store_true', dest='createindices', default=False,
                       help='Create primary keys and their indices')
    parser.add_argument('-v', action='store_true', dest='verbose', default=False,
                       help='Enable verbose output.')
    parser.add_argument('inputfile', nargs='?', default="-",
                        help='OSM input file')

    options = parser.parse_args()

    mgr = BaseImportManager(options.database, options.verbose)
    if options.replication:
        mgr.set_replication_source(options.replication)

    if options.createdb:
        mgr.create_database()
    else:
        if not database_exists(options.database):
            raise RuntimeError("Database does not exist.")

    importer = OSMImporter(options)
    importer.readfile()
    if options.createindices:
        importer.create_indices()
    if options.ro_user:
        importer.grant_read_access(options.ro_user)
